python main_pretrain.py \
    --data_path /home/gzg2104/uncertainty_mae/dataset_generation/columbia_emoji/train \
    --dataset_name emoji \
    --batch_size 256 \
    --blr 2e-4 \
    --accum_iter 1 \
    --output_dir /local/zemel/gzg2104/_emoji_models/06_04_24_beta_20_invisible_lr_0_1_decay_0_05_RESTART_lr_2e-4 \
    --log_dir /local/zemel/gzg2104/_emoji_models/06_04_24_beta_20_invisible_lr_0_1_decay_0_05_RESTART_lr_2e-4 \
    --model mae_vit_base_patch16 \
    --warmup_epochs 40 \
    --epochs 4000 \
    --log_freq 200 \
    --vae \
    --kld_beta 20 \
    --invisible_lr_scale 0.1 \
    --mask_ratio 0.75 \
    --partial_vae \
    --dropout_ratio 0 \
    --eps 1e-4 \
    --weight_decay 0.05 \
    --mixed_precision \
    --resume /local/zemel/gzg2104/_emoji_models/06_02_24_beta_20_invisible_lr_0_1_decay_0_05/checkpoint-2000.pth